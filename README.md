# Assignment3
Контрольные вопросы к Assignment 3

1. Какие основные типы памяти существуют в архитектуре CUDA и чем они отличаются по скорости доступа?
● Глобальная память: доступна всем потокам, но медленная по сравнению с другими типами памяти.
● Разделяемая память: быстрая память, доступная всем потокам в пределах одного блока. Используется для
обмена данными между потоками внутри одного блока.
● Регистры: самая быстрая память, но доступна только каждому потоку для собственных данных.
● Константная память: используется для хранения неизменяемых данных, доступна всем потокам.
2. В каких случаях использование разделяемой памяти позволяет ускорить выполнение CUDA-программы?
Использование разделяемой памяти (Shared Memory) ускоряет CUDA-программы, когда потоки в одном блоке многократно обращаются к одним и тем же данным из медленной глобальной памяти, или для обмена данными между потоками одного блока.
3. Как шаблон доступа к глобальной памяти влияет на производительность GPU программы?
Понимание и правильное проектирование шаблона доступа к памяти (например, использование коалесценции, минимизация случайных обращений, эффективное применение кэшей и общей памяти) — один из ключевых факторов для достижения максимальной производительности в GPU-программах
4. Почему одинаковый алгоритм на GPU может показывать разное время выполнения при разных способах обращения к памяти?
Потому что память на GPU имеет иерархию и разную пропускную способность.
5. Как размер блока потоков влияет на производительность CUDA-ядра?
Размер блока потоков определяет:
загруженность SM (Streaming Multiprocessor)
число активных варпов
occupancy (степень использования ресурсов)
6. Что такое варп и почему важно учитывать его при разработке CUDA-программ?
Варп (warp) — это группа из 32 потоков, которые выполняются одновременно одной инструкцией.
Почему это важно: Ветвления внутри варпа → warp divergence, Если потоки идут по разным if → они выполняются последовательно, Это снижает параллелизм
7. Какие факторы необходимо учитывать при выборе конфигурации сетки и блоковпотоков?
Основные факторы:
Размер задачи
Архитектура GPU
Использование ресурсов
Occupancy
Доступ к памяти
Размер варпа (32)
8. Почему оптимизация CUDA-программы часто начинается с анализа работы с памятью, а не с изменения алгоритма?
Потому что GPU чаще ограничен памятью, а не вычислениями.
